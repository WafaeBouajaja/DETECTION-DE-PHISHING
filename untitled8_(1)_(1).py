# -*- coding: utf-8 -*-
"""Untitled8_(1)_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B2O8c59fVGM5VgfaS0VJxlM_0yoj9QV1
"""





import pandas as pd


df = pd.read_csv("/content/phishing.csv")


df.head()

# Taille du dataset
print("Nombre de lignes et colonnes :", df.shape)

# Types de donn√©es
print(df.dtypes)

# R√©sum√© statistique
print(df.describe())

# Valeurs manquantes
print(df.isnull().sum())

# Supprimer les colonnes inutiles si besoin
df = df.drop(columns=["index", "id"], errors='ignore')  # √† adapter selon le dataset

# Supprimer les doublons
df = df.drop_duplicates()

# Supprimer ou remplir les valeurs manquantes
df = df.dropna()

import seaborn as sns
import matplotlib.pyplot as plt

# Visualisation des classes phishing vs l√©gitimes
sns.countplot(x='class', data=df)
plt.title("R√©partition des sites : Phishing vs L√©gitime")
plt.xlabel("Classe (1 = phishing, -1 = l√©gitime)")  # ou adapte selon ta compr√©hension
plt.ylabel("Nombre d'exemples")
plt.show()

# ‚úÖ 1. S√©parer X (les caract√©ristiques) et y (la cible)
X = df.drop(['Index', 'class'], axis=1)  # on enl√®ve l‚Äôindex et la classe
y = df['class']

# ‚úÖ 2. V√©rifier les dimensions
print("Dimensions de X :", X.shape)
print("Dimensions de y :", y.shape)

# ‚úÖ 3. Exemple de valeurs
print("Exemples de X :")
print(X.head())

print("Exemples de y :")
print(y.value_counts())

pip install pandas scikit-learn joblib streamlit

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import os

# 1. Charger les donn√©es avec gestion d'erreurs
try:
    # Ajustez le chemin selon votre environnement
    # Pour Colab: '/content/phishing.csv'
    # Pour local: 'phishing.csv' ou le chemin complet
    df = pd.read_csv('phishing.csv')
    print(f"Dataset charg√© avec succ√®s: {df.shape}")
    print("Colonnes disponibles:")
    print(df.columns.tolist())

except FileNotFoundError:
    print("‚ùå Erreur: Fichier 'phishing.csv' non trouv√©")
    print("V√©rifiez le chemin du fichier")
    exit()

# 2. Exploration rapide des donn√©es
print(f"\nInformations sur le dataset:")
print(f"Shape: {df.shape}")
print(f"Valeurs manquantes: {df.isnull().sum().sum()}")

# V√©rifier les noms de colonnes possibles pour la variable cible
target_candidates = ['CLASS_LABEL', 'class', 'label', 'target', 'phishing']
target_col = None

for col in target_candidates:
    if col in df.columns:
        target_col = col
        break

if target_col is None:
    print("‚ùå Erreur: Colonne cible non trouv√©e")
    print("Colonnes disponibles:", df.columns.tolist())
    exit()

print(f"Colonne cible utilis√©e: {target_col}")
print(f"Distribution des classes: \n{df[target_col].value_counts()}")

# 3. Pr√©paration des donn√©es
X = df.drop(target_col, axis=1)
y = df[target_col]

# Mapper les labels si n√©cessaire (-1/1 vers 0/1)
if y.min() == -1:
    y = y.map({-1: 0, 1: 1})
    print("Labels mapp√©s de {-1, 1} vers {0, 1}")

# V√©rifier s'il y a des colonnes non-num√©riques
non_numeric = X.select_dtypes(exclude=[np.number]).columns
if len(non_numeric) > 0:
    print(f"‚ö†Ô∏è Colonnes non-num√©riques d√©tect√©es: {non_numeric.tolist()}")
    # Vous pourriez vouloir les encoder ou les supprimer
    X = X.select_dtypes(include=[np.number])
    print(f"Utilisation des colonnes num√©riques seulement: {X.shape}")

# 4. Division train/test
print(f"\nDivision des donn√©es...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
print(f"Train: {X_train.shape}, Test: {X_test.shape}")

# 5. Normalisation
print("Normalisation des donn√©es...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. Mod√®le de base
print("\n" + "="*50)
print("MOD√àLE RANDOM FOREST - VERSION DE BASE")
print("="*50)

rf_base = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    n_jobs=-1
)
rf_base.fit(X_train_scaled, y_train)

y_pred_base = rf_base.predict(X_test_scaled)

print(f"Accuracy: {accuracy_score(y_test, y_pred_base):.4f}")
print(f"\nMatrice de confusion:")
print(confusion_matrix(y_test, y_pred_base))
print(f"\nRapport de classification:")
print(classification_report(y_test, y_pred_base))

# 7. Optimisation des hyperparam√®tres
print("\n" + "="*50)
print("OPTIMISATION DES HYPERPARAM√àTRES")
print("="*50)

param_grid = {
    'n_estimators': [100, 150, 200],
    'max_depth': [None, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2]
}

print("Recherche des meilleurs param√®tres...")
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42, n_jobs=-1),
    param_grid=param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_scaled, y_train)

print(f"Meilleurs param√®tres: {grid_search.best_params_}")
print(f"Meilleur score F1 (CV): {grid_search.best_score_:.4f}")

# 8. √âvaluation du mod√®le optimis√©
print("\n" + "="*50)
print("MOD√àLE OPTIMIS√â - √âVALUATION FINALE")
print("="*50)

best_rf = grid_search.best_estimator_
y_pred_optimized = best_rf.predict(X_test_scaled)

print(f"Accuracy: {accuracy_score(y_test, y_pred_optimized):.4f}")
print(f"\nMatrice de confusion:")
print(confusion_matrix(y_test, y_pred_optimized))
print(f"\nRapport de classification:")
print(classification_report(y_test, y_pred_optimized))

# 9. Importance des features
print("\n" + "="*50)
print("IMPORTANCE DES FEATURES (TOP 10)")
print("="*50)

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': best_rf.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance.head(10))

# 10. Sauvegarde des mod√®les
print("\n" + "="*50)
print("SAUVEGARDE DES MOD√àLES")
print("="*50)

try:
    # Cr√©er le dossier models s'il n'existe pas
    os.makedirs('models', exist_ok=True)

    # Sauvegarder le mod√®le et le scaler
    joblib.dump(best_rf, 'models/phishing_rf_model.pkl')
    joblib.dump(scaler, 'models/phishing_scaler.pkl')

    print("‚úÖ Mod√®le sauvegard√©: models/phishing_rf_model.pkl")
    print("‚úÖ Scaler sauvegard√©: models/phishing_scaler.pkl")

    # Sauvegarder aussi les noms des colonnes
    joblib.dump(X.columns.tolist(), 'models/feature_names.pkl')
    print("‚úÖ Noms des features sauvegard√©s: models/feature_names.pkl")

except Exception as e:
    print(f"‚ùå Erreur lors de la sauvegarde: {e}")

print("\n" + "="*50)
print("ENTRA√éNEMENT TERMIN√â !")
print("="*50)

import streamlit as st
import numpy as np
import joblib
import os
import pandas as pd

st.set_page_config(
    page_title="D√©tection de Phishing",
    page_icon="üîç",
    layout="wide"
)

st.title("üîç D√©tection de Phishing")
st.markdown("---")

# V√©rification et chargement des mod√®les
@st.cache_resource
def load_models():
    try:
        # Chemins possibles pour les mod√®les
        model_paths = [
            'models/phishing_rf_model.pkl',
            'phishing_rf.pkl',
            'phishing_rf_model.pkl',
            './models/phishing_rf_model.pkl',
            '../models/phishing_rf_model.pkl'
        ]

        scaler_paths = [
            'models/phishing_scaler.pkl',
            'phishing_scaler.pkl',
            './models/phishing_scaler.pkl',
            '../models/phishing_scaler.pkl'
        ]

        model = None
        scaler = None

        # Charger le mod√®le
        for path in model_paths:
            if os.path.exists(path):
                model = joblib.load(path)
                st.success(f"‚úÖ Mod√®le charg√© depuis: {path}")
                break

        # Charger le scaler
        for path in scaler_paths:
            if os.path.exists(path):
                scaler = joblib.load(path)
                st.success(f"‚úÖ Scaler charg√© depuis: {path}")
                break

        if model is None:
            st.error("‚ùå Mod√®le non trouv√©. V√©rifiez les chemins ou ex√©cutez l'entra√Ænement.")
            st.info("üí° Chemins recherch√©s: " + ", ".join(model_paths))
            return None, None

        if scaler is None:
            st.warning("‚ö†Ô∏è Scaler non trouv√©. Utilisation sans normalisation.")

        return model, scaler

    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement: {str(e)}")
        return None, None

# D√©finir les descriptions des caract√©ristiques
feature_descriptions = {
    "having_IP_Address": "Utilise une adresse IP au lieu d'un nom de domaine",
    "URL_Length": "Longueur de l'URL",
    "Shortining_Service": "Utilise un service de raccourcissement d'URL",
    "having_At_Symbol": "Contient le symbole @ dans l'URL",
    "double_slash_redirecting": "Double slash de redirection",
    "Prefix_Suffix": "Pr√©fixe-suffixe dans le nom de domaine",
    "having_Sub_Domain": "Nombre de sous-domaines",
    "SSLfinal_State": "√âtat du certificat SSL",
    "Domain_registeration_length": "Dur√©e d'enregistrement du domaine",
    "Favicon": "Favicon charg√© depuis un domaine externe",
    "port": "Utilise un port non-standard",
    "HTTPS_token": "Token HTTPS dans le nom de domaine",
    "Request_URL": "Pourcentage d'objets charg√©s depuis un autre domaine",
    "URL_of_Anchor": "URLs des ancres",
    "Links_in_tags": "Liens dans les balises META, SCRIPT et LINK",
    "SFH": "Server Form Handler",
    "Submitting_to_email": "Soumission √† une adresse email",
    "Abnormal_URL": "URL anormale",
    "Redirect": "Redirection",
    "on_mouseover": "Changement de statut sur mouseover",
    "RightClick": "D√©sactivation du clic droit",
    "popUpWidnow": "Fen√™tres popup",
    "Iframe": "Utilisation d'IFrame",
    "age_of_domain": "√Çge du domaine",
    "DNSRecord": "Enregistrement DNS",
    "web_traffic": "Trafic web",
    "Page_Rank": "Classement de page",
    "Google_Index": "Indexation Google",
    "Links_pointing_to_page": "Liens pointant vers la page",
    "Statistical_report": "Rapport statistique"
}

# Charger les mod√®les
model, scaler = load_models()

if model is not None:

    # Section pour URL rapide (optionnelle)
    st.markdown("### üöÄ Test rapide avec des valeurs pr√©d√©finies")
    col_test1, col_test2 = st.columns(2)

    with col_test1:
        if st.button("üü¢ Tester un site l√©gitime"):
            st.session_state.test_values = [0] * 30  # Valeurs s√ªres

    with col_test2:
        if st.button("üî¥ Tester un site suspect"):
            st.session_state.test_values = [1, 1, 1, 1, 0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]

    st.markdown("---")
    st.markdown("### üìä Analyse d√©taill√©e")
    st.markdown("Ajustez les param√®tres ci-dessous pour analyser un site web:")

    # Cr√©er les inputs avec des descriptions
    inputs = []
    feature_names = list(feature_descriptions.keys())

    # Utiliser un expander pour une meilleure organisation
    with st.expander("üîß Param√®tres avanc√©s", expanded=True):
        # Cr√©er les colonnes
        num_cols = 3
        cols = st.columns(num_cols)

        for i, feature_name in enumerate(feature_names):
            col_idx = i % num_cols

            with cols[col_idx]:
                # Utiliser les valeurs de test si elles existent
                default_val = 0.0
                if hasattr(st.session_state, 'test_values') and st.session_state.test_values:
                    default_val = float(st.session_state.test_values[i])

                val = st.number_input(
                    feature_name,
                    value=default_val,
                    help=feature_descriptions[feature_name],
                    key=f"input_{i}",
                    min_value=-1.0,
                    max_value=10.0,
                    step=0.1
                )
                inputs.append(val)

    # Bouton d'analyse centr√©
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        analyze_button = st.button("üîç Analyser le site", type="primary", use_container_width=True)

    if analyze_button:
        try:
            X = np.array(inputs).reshape(1, -1)

            # Appliquer le scaler si disponible
            if scaler is not None:
                X_scaled = scaler.transform(X)
            else:
                X_scaled = X

            prediction = model.predict(X_scaled)[0]
            probabilities = model.predict_proba(X_scaled)[0]

            st.markdown("---")
            st.markdown("### üìã R√©sultats de l'analyse")

            if prediction == 1:
                st.error(f"‚ö†Ô∏è **SITE SUSPECT - PHISHING D√âTECT√â !**")
                st.error(f"üéØ Probabilit√© de phishing: **{probabilities[1]:.1%}**")
                st.warning("üõ°Ô∏è **Recommandation**: Ne pas visiter ce site ou saisir d'informations personnelles")
            else:
                st.success(f"‚úÖ **SITE PROBABLEMENT L√âGITIME**")
                st.success(f"üéØ Probabilit√© de l√©gitimit√©: **{probabilities[0]:.1%}**")
                st.info("‚ÑπÔ∏è **Note**: Cette analyse est bas√©e sur des caract√©ristiques techniques. Restez vigilant.")

            # Afficher les probabilit√©s d√©taill√©es
            col_prob1, col_prob2 = st.columns(2)
            with col_prob1:
                st.metric("Probabilit√© L√©gitime", f"{probabilities[0]:.1%}")
            with col_prob2:
                st.metric("Probabilit√© Phishing", f"{probabilities[1]:.1%}")

        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'analyse: {str(e)}")
            st.info("üí° V√©rifiez que les valeurs sont dans les bonnes plages")

else:
    st.error("‚ùå Impossible de charger les mod√®les.")

import numpy as np
import joblib
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

def load_or_create_model():
    """Charge le mod√®le ou en cr√©e un de d√©monstration si les fichiers n'existent pas"""
    model_path = 'phishing_rf.pkl'
    scaler_path = 'phishing_scaler.pkl'

    try:
        # Tentative de chargement des mod√®les existants
        if os.path.exists(model_path) and os.path.exists(scaler_path):
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            print("‚úÖ Mod√®les charg√©s avec succ√®s!")
            return model, scaler
        else:
            raise FileNotFoundError("Fichiers de mod√®le non trouv√©s")

    except Exception as e:
        print(f"‚ö†Ô∏è Impossible de charger les mod√®les: {str(e)}")
        print("üîß Cr√©ation d'un mod√®le de d√©monstration...")

        # Cr√©ation d'un mod√®le de d√©monstration
        np.random.seed(42)
        X_demo = np.random.randn(1000, 30)
        # R√®gle simple pour cr√©er des labels
        y_demo = (X_demo[:, :5].sum(axis=1) > 0).astype(int)

        # Entra√Ænement du mod√®le de d√©monstration
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        scaler = StandardScaler()

        X_scaled = scaler.fit_transform(X_demo)
        model.fit(X_scaled, y_demo)

        # Sauvegarde optionnelle
        try:
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            print("üíæ Mod√®le de d√©monstration sauvegard√©")
        except:
            print("Impossible de sauvegarder le mod√®le")

        return model, scaler

def get_user_input():
    """R√©cup√®re les 30 caract√©ristiques de l'utilisateur"""
    print("\nüîç D√âTECTEUR DE PHISHING")
    print("=" * 50)
    print("Veuillez entrer les 30 caract√©ristiques (valeurs entre -3 et 3 recommand√©es)")
    print("Appuyez sur Entr√©e pour utiliser la valeur par d√©faut (0.0)")
    print("-" * 50)

    inputs = []
    for i in range(30):
        while True:
            try:
                user_input = input(f"Feature_{i+1:02d}: ")
                if user_input.strip() == "":
                    val = 0.0
                else:
                    val = float(user_input)
                inputs.append(val)
                break
            except ValueError:
                print("‚ùå Veuillez entrer un nombre valide!")

    return inputs

def generate_random_input():
    """G√©n√®re des valeurs al√©atoires pour test"""
    return np.random.randn(30).tolist()

def predict_phishing(model, scaler, inputs):
    """Effectue la pr√©diction de phishing"""
    try:
        # Pr√©paration des donn√©es
        X = np.array(inputs).reshape(1, -1)
        Xs = scaler.transform(X)

        # Pr√©diction
        pred = model.predict(Xs)[0]
        probabilities = model.predict_proba(Xs)[0]
        prob_phishing = probabilities[1] if len(probabilities) > 1 else probabilities[0]
        prob_legitimate = probabilities[0] if len(probabilities) > 1 else 1 - probabilities[0]

        return pred, prob_phishing, prob_legitimate

    except Exception as e:
        print(f"‚ùå Erreur lors de la pr√©diction: {str(e)}")
        return None, None, None

def display_results(pred, prob_phishing, prob_legitimate):
    """Affiche les r√©sultats de la pr√©diction"""
    print("\n" + "=" * 50)
    print("üìä R√âSULTATS DE L'ANALYSE")
    print("=" * 50)

    if pred == 1:
        print("‚ö†Ô∏è  PHISHING D√âTECT√â ‚ö†Ô∏è")
        print(f"Probabilit√© de phishing: {prob_phishing:.2%}")
    else:
        print("‚úÖ SITE L√âGITIME ‚úÖ")
        print(f"Probabilit√© de l√©gitimit√©: {prob_legitimate:.2%}")

    print(f"\nD√©tail des probabilit√©s:")
    print(f"  - L√©gitime: {prob_legitimate:.2%}")
    print(f"  - Phishing: {prob_phishing:.2%}")
    print("-" * 50)

def main():
    """Fonction principale"""
    try:
        # Chargement du mod√®le
        model, scaler = load_or_create_model()

        while True:
            print("\n" + "=" * 50)
            print("OPTIONS:")
            print("1. Entrer les valeurs manuellement")
            print("2. G√©n√©rer des valeurs al√©atoires")
            print("3. Quitter")
            print("=" * 50)

            choice = input("Votre choix (1-3): ").strip()

            if choice == '1':
                inputs = get_user_input()
            elif choice == '2':
                inputs = generate_random_input()
                print("üé≤ Valeurs al√©atoires g√©n√©r√©es:")
                for i, val in enumerate(inputs):
                    print(f"Feature_{i+1:02d}: {val:.3f}")
            elif choice == '3':
                print("üëã Au revoir!")
                break
            else:
                print("‚ùå Choix invalide!")
                continue

            # Pr√©diction
            pred, prob_phishing, prob_legitimate = predict_phishing(model, scaler, inputs)

            if pred is not None:
                display_results(pred, prob_phishing, prob_legitimate)

            # Demander si continuer
            continue_choice = input("\nVoulez-vous faire une autre pr√©diction? (o/n): ").strip().lower()
            if continue_choice not in ['o', 'oui', 'y', 'yes']:
                print("üëã Au revoir!")
                break

    except KeyboardInterrupt:
        print("\n\nüëã Programme interrompu. Au revoir!")
    except Exception as e:
        print(f"‚ùå Erreur critique: {str(e)}")

if __name__ == "__main__":
    main()



